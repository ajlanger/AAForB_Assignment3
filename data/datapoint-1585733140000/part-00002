{"title_page": "Fieller's theorem", "text_new": "In [[statistics]], '''Fieller's theorem''' allows the calculation of a [[confidence interval]] for the ratio of two [[arithmetic mean|means]].\n\n==Approximate confidence interval==\nVariables ''a'' and ''b'' may be measured in different units, so there is no way to directly combine the [[standard error]]s as they may also be in different units. The most complete discussion of this is given by Fieller (1954).<ref>{{cite journal |author=Fieller, EC. |title=Some problems in interval estimation. |journal=[[Journal of the Royal Statistical Society, Series B]] |volume=16 |issue= 2|pages=175\u2013185 |year=1954 |jstor=2984043 }}</ref>\n\nFieller showed that if ''a'' and ''b'' are (possibly [[correlation|correlated]]) [[sample mean|means of two samples]] with [[expected value|expectations]] <math>\\mu_a</math> and <math>\\mu_b</math>, and variances <math>\\nu_{11}\\sigma^2</math> and <math>\\nu_{22}\\sigma^2</math> and covariance <math>\\nu_{12}\\sigma^2</math>, and if <math>\\nu_{11}, \\nu_{12}, \\nu_{22} </math> are all known, then a (1&nbsp;&minus;&nbsp;''\u03b1'') confidence interval (''m''<sub>L</sub>,&nbsp;''m''<sub>U</sub>) for <math>\\mu_a/\\mu_b</math> is given by\n\n: <math>(m_L, m_{U}) = \\frac{1}{(1-g)} \\left[\\frac{a}{b} - \\frac{g\\nu_{12}}{\\nu_{22}} \\mp \\frac{t_{r,\\alpha}s}{b} \\sqrt{\\nu_{11} - 2\\frac{a}{b}\\nu_{12} + \\frac{a^2}{b^2} \\nu_{22} - g\\left(\\nu_{11} - \\frac{\\nu_{12}^2}{\\nu_{22}}\\right)} \\right]</math>\n\nwhere\n:<math>g=\\frac{t^{2}_{r,\\alpha}s^2\\nu_{22}}{b^2}.</math>\nHere <math>s^2</math> is an [[bias of an estimator|unbiased estimator]] of <math>\\sigma^2</math> based on r degrees of freedom, and <math>t_{r,\\alpha}</math> is the <math>\\alpha</math>-level deviate from the [[Student's t-distribution]] based on ''r'' degrees of freedom.\n\nThree features of this formula are important in this context:\n\na) The expression inside the square root has to be positive, or else the resulting interval will be imaginary.\n\nb) When ''g'' is very close to 1, the confidence interval is infinite.\n\nc) When ''g'' is greater than 1, the overall divisor outside the square brackets is negative and the confidence interval is exclusive.\n\n== Other methods ==\n\nOne problem is that, when ''g'' is not small, the confidence interval can blow up when using Fieller's theorem. Andy Grieve has provided a Bayesian solution where the CIs are still sensible, albeit wide.<ref>{{cite journal |vauthors=O'Hagan A, Stevens JW, Montmartin J | title=Inference for the cost-effectiveness acceptability curve and cost-effectiveness ratio. |journal=[[PharmacoEconomics (journal)|Pharmacoeconomics]] |volume=17|issue=4 |pages=339\u201349 |year=2000 |doi=10.2165/00019053-200017040-00004 |pmid=10947489}}</ref> [[Bootstrapping (statistics)|Bootstrapping]] provides another alternative that does not require the assumption of normality.<ref>{{cite journal|last=Campbell|first=M. K.|author2=Torgerson, D. J.|journal=[[QJM: An International Journal of Medicine]]|year=1999|volume=92|issue=3|pages=177\u2013182|doi=10.1093/qjmed/92.3.177|title=Bootstrapping: estimating confidence intervals for cost-effectiveness ratios}}</ref>\n\n== History ==\nEdgar C. Fieller (1907&ndash;1960) first started working on this problem while in [[Karl Pearson]]'s group at [[University College London]], where he was employed for five years after graduating in Mathematics from [[King's College, Cambridge]]. He then worked for the [[Boots UK|Boots Pure Drug Company]] as a statistician and [[operational research]]er before becoming deputy head of operational research at [[RAF Fighter Command]] during the [[Second World War]], after which he was appointed the first head of the Statistics Section at the [[National Physical Laboratory (United Kingdom)|National Physical Laboratory]].<ref>{{cite journal |author1=Irwin, J. O.  |author2=Rest, E. D. Van | title=Edgar Charles Fieller, 1907-1960 |journal=Journal of the Royal Statistical Society, Series A |volume=124 |issue=2 |pages=275\u2013277 |year=1961 | jstor=2984155 |publisher=Blackwell Publishing}}</ref>\n\n==See also==\n*[[Ratio distribution#Gaussian ratio distribution|Gaussian ratio distribution]]\n\n== Notes ==\n{{reflist}}\n\n== Further reading ==\n* {{cite journal | last1 = Pigeot | first1 = Iris | last2 = Schafer | first2 = Juliane | last3 = Rohmel | first3 = Joachim | last4 = Hauschke | first4 = Dieter | year = 2003 | title = Assessing non-inferiority of a new treatment in a three-arm clinical trial including a placebo | url = | journal = [[Statistics in Medicine (journal)|Statistics in Medicine]] | volume = 22 | issue = 6| pages = 883\u2013899 | doi = 10.1002/sim.1450 }}\n* {{cite journal | last1 = Fieller | first1 = EC | year = 1932 | title = The distribution of the index in a bivariate Normal distribution | url = | journal = [[Biometrika]] | volume = 24 | issue = 3\u20134| pages = 428\u2013440 | doi = 10.1093/biomet/24.3-4.428 }}\n* Fieller, EC. (1940) \"The biological standardisation of insulin\". ''[[Journal of the Royal Statistical Society]] (Supplement)''. 1:1&ndash;54. {{jstor|2983630}}\n* {{cite journal | last1 = Fieller | first1 = EC | year = 1944 | title = A fundamental formula in the statistics of biological assay, and some applications | url = | journal = Quarterly Journal of Pharmacy and Pharmacology | volume = 17 | issue = | pages = 117\u2013123 }}\n* Motulsky, Harvey (1995) ''Intuitive Biostatistics''. Oxford University Press. {{ISBN|0-19-508607-4}}\n* Senn, Steven (2007) ''Statistical Issues in Drug Development''. Second Edition. Wiley. {{ISBN|0-471-97488-9}}\n*{{Cite journal| volume = 64 | pages = 234\u2013241 | year = 2010 | doi = 10.1198/tast.2010.08130 | last1 = Hirschberg | journal = [[The American Statistician]] | first1 = J.| title = A Geometric Comparison of the Delta and Fieller Confidence Intervals| last2 = Lye |first2 = J. | issue = 3}}\n\n{{DEFAULTSORT:Fieller's Theorem}}\n[[Category:Statistical theorems]]\n[[Category:Statistical approximations]]\n[[Category:Normal distribution]]\n", "text_old": "In [[statistics]], '''Fieller's theorem''' allows the calculation of a [[confidence interval]] for the ratio of two [[arithmetic mean|means]].\n\n==Approximate confidence interval==\nVariables ''a'' and ''b'' may be measured in different units, so there is no way to directly combine the [[standard error]]s as they may also be in different units. The most complete discussion of this is given by Fieller (1954).<ref>{{cite journal |author=Fieller, EC. |title=Some problems in interval estimation. |journal=[[Journal of the Royal Statistical Society, Series B]] |volume=16 |issue= 2|pages=175\u2013185 |year=1954 |jstor=2984043 }}</ref>\n\nFieller showed that if ''a'' and ''b'' are (possibly [[correlation|correlated]]) [[sample mean|means of two samples]] with [[expected value|expectations]] <math>\\mu_a</math> and <math>\\mu_b</math>, and variances <math>\\nu_{11}\\sigma^2</math> and <math>\\nu_{22}\\sigma^2</math> and covariance <math>\\nu_{12}\\sigma^2</math>, and if <math>\\nu_{11}, \\nu_{12}, \\nu_{22} </math> are all known, then a (1&nbsp;&minus;&nbsp;''\u03b1'') confidence interval (''m''<sub>L</sub>,&nbsp;''m''<sub>U</sub>) for <math>\\mu_a/\\mu_b</math> is given by\n\n: <math>(m_L, m_{U}) = \\frac{1}{(1-g)} \\left[\\frac{a}{b} - \\frac{g\\nu_{12}}{\\nu_{22}} \\mp \\frac{t_{r,\\alpha}s}{b} \\sqrt{\\nu_{11} - 2\\frac{a}{b}\\nu_{12} + \\frac{a^2}{b^2} \\nu_{22} - g\\left(\\nu_{11} - \\frac{\\nu_{12}^2}{\\nu_{22}}\\right)} \\right]</math>\n\nwhere\n:<math>g=\\frac{t^{2}_{r,\\alpha}s^2\\nu_{22}}{b^2}.</math>\nHere <math>s^2</math> is an [[bias of an estimator|unbiased estimator]] of <math>\\sigma^2</math> based on r degrees of freedom, and <math>t_{r,\\alpha}</math> is the <math>\\alpha</math>-level deviate from the [[Student's t-distribution]] based on ''r'' degrees of freedom.\n\nThree features of this formula are important in this context:\n\na) The expression inside the square root has to be positive, or else the resulting interval will be imaginary.\n\nb) When ''g'' is very close to 1, the confidence interval is infinite.\n\nc) When ''g'' is greater than 1, the overall divisor outside the square brackets is negative and the confidence interval is exclusive.\n\n== Other methods ==\n\nOne problem is that, when ''g'' is not small, the confidence interval can blow up when using Fieller's theorem. Andy Grieve has provided a Bayesian solution where the CIs are still sensible, albeit wide.<ref>{{cite journal |vauthors=O'Hagan A, Stevens JW, Montmartin J | title=Inference for the cost-effectiveness acceptability curve and cost-effectiveness ratio. |journal=[[PharmacoEconomics (journal)|Pharmacoeconomics]] |volume=17|issue=4 |pages=339\u201349 |year=2000 |doi=10.2165/00019053-200017040-00004 |pmid=10947489}}</ref> [[Bootstrapping (statistics)|Bootstrapping]] provides another alternative that does not require the assumption of normality.<ref>{{cite journal|last=Campbell|first=M. K.|author2=Torgerson, D. J.|journal=[[QJM: An International Journal of Medicine]]|year=1999|volume=92|issue=3|pages=177\u2013182|doi=10.1093/qjmed/92.3.177|title=Bootstrapping: estimating confidence intervals for cost-effectiveness ratios}}</ref>\n\n== History ==\nEdgar C. Fieller (1907&ndash;1960) first started working on this problem while in [[Karl Pearson]]'s group at [[University College London]], where he was employed for five years after graduating in Mathematics from [[King's College, Cambridge]]. He then worked for the [[Boots UK|Boots Pure Drug Company]] as a statistician and [[operational research]]er before becoming deputy head of operational research at [[RAF Fighter Command]] during the [[Second World War]], after which he was appointed the first head of the Statistics Section at the [[National Physical Laboratory (United Kingdom)|National Physical Laboratory]].<ref>{{cite journal |author1=Irwin, J. O.  |author2=Rest, E. D. Van | title=Edgar Charles Fieller, 1907-1960 |journal=Journal of the Royal Statistical Society, Series A |volume=124 |issue=2 |pages=275\u2013277 |year=1961 | jstor=2984155 |publisher=Blackwell Publishing}}</ref>\n\n==See also==\n*[[Ratio distribution#Gaussian ratio distribution|Gaussian ratio distribution]]\n\n== Notes ==\n{{reflist}}\n\n== Further reading ==\n* Iris Pigeot, Juliane Schafer, Joachim Rohmel and Dieter Hauschke (2003) \"Assessing non-inferiority of a new treatment in a three-arm clinical trial including a placebo\". ''[[Statistics in Medicine (journal)|Statistics in Medicine]]'', 22:883\u2013899, {{doi| 10.1002/sim.1450}}\n* Fieller, EC. (1932) \"The distribution of the index in a bivariate Normal distribution\". ''[[Biometrika]]'', 24(3&ndash;4):428&ndash;440. {{doi| 10.1093/biomet/24.3-4.428}}\n* Fieller, EC. (1940) \"The biological standardisation of insulin\". ''[[Journal of the Royal Statistical Society]] (Supplement)''. 1:1&ndash;54. {{jstor|2983630}}\n* Fieller, EC. (1944) \"A fundamental formula in the statistics of biological assay, and some applications\". ''Quarterly Journal of Pharmacy and Pharmacology''. 17: 117-123.\n* Motulsky, Harvey (1995) ''Intuitive Biostatistics''. Oxford University Press. {{ISBN|0-19-508607-4}}\n* Senn, Steven (2007) ''Statistical Issues in Drug Development''. Second Edition. Wiley. {{ISBN|0-471-97488-9}}\n*{{Cite journal| volume = 64 | pages = 234\u2013241 | year = 2010 | doi = 10.1198/tast.2010.08130 | last1 = Hirschberg | journal = [[The American Statistician]] | first1 = J.| title = A Geometric Comparison of the Delta and Fieller Confidence Intervals| last2 = Lye |first2 = J. | issue = 3}}\n\n{{DEFAULTSORT:Fieller's Theorem}}\n[[Category:Statistical theorems]]\n[[Category:Statistical approximations]]\n[[Category:Normal distribution]]\n", "name_user": "Rjwilmsi", "label": "safe", "comment": "\u2192\u200eFurther reading:Journal cites:, templated 2 journal cites, added 1 issue number", "url_page": "//en.wikipedia.org/wiki/Fieller%27s_theorem"}
